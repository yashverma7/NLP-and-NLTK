{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CosineSimilarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFOqrJb1HR-"
      },
      "source": [
        "Uploading the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "L8QzTv03QvSI",
        "outputId": "b23e6b1a-29ef-41f8-82da-4e9f0f6723c1"
      },
      "source": [
        "from google.colab import files\n",
        "files = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afdc5eca-5cc0-460b-b134-232a97a05a0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afdc5eca-5cc0-460b-b134-232a97a05a0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Article.txt to Article.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yVV4iIM1Lmg"
      },
      "source": [
        "Reading the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpqF7s4Yyvzs",
        "outputId": "5078dbba-3ee4-4149-d52e-76eb5cd7bb9b"
      },
      "source": [
        "r=open(\"Article.txt\",\"r\")\n",
        "d=r.read()\n",
        "print(d)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep learning helps robots grasp and move objects with ease\n",
            "Combining neural networks with motion planning software gives robots the speed and skill to assist in warehouse environments\n",
            "Date:\n",
            "November 18, 2020\n",
            "Source:\n",
            "University of California - Berkeley\n",
            "Summary:\n",
            "Researchers have created new artificial intelligence software that gives robots the speed and skill to grasp and smoothly move objects, making it feasible for them to soon assist humans in warehouse environments.\n",
            "\n",
            "    \n",
            "FULL STORY\n",
            "In the past year, lockdowns and other COVID-19 safety measures have made online shopping more popular than ever, but the skyrocketing demand is leaving many retailers struggling to fulfill orders while ensuring the safety of their warehouse employees.\n",
            "\n",
            "Researchers at the University of California, Berkeley, have created new artificial intelligence software that gives robots the speed and skill to grasp and smoothly move objects, making it feasible for them to soon assist humans in warehouse environments. The technology is described in a paper published online today (Wednesday, Nov. 18) in the journal Science Robotics.\n",
            "\n",
            "Automating warehouse tasks can be challenging because many actions that come naturally to humans -- like deciding where and how to pick up different types of objects and then coordinating the shoulder, arm and wrist movements needed to move each object from one location to another -- are actually quite difficult for robots. Robotic motion also tends to be jerky, which can increase the risk of damaging both the products and the robots.\n",
            "\n",
            "\"Warehouses are still operated primarily by humans, because it's still very hard for robots to reliably grasp many different objects,\" said Ken Goldberg, William S. Floyd Jr. Distinguished Chair in Engineering at UC Berkeley and senior author of the study. \"In an automobile assembly line, the same motion is repeated over and over again, so that it can be automated. But in a warehouse, every order is different.\"\n",
            "\n",
            "In earlier work, Goldberg and UC Berkeley postdoctoral researcher Jeffrey Ichnowski created a Grasp-Optimized Motion Planner that could compute both how a robot should pick up an object and how it should move to transfer the object from one location to another.\n",
            "\n",
            "However, the motions generated by this planner were jerky. While the parameters of the software could be tweaked to generate smoother motions, these calculations took an average of about half a minute to compute.\n",
            "\n",
            "In the new study, Goldberg and Ichnowski, in collaboration with UC Berkeley graduate student Yahav Avigal and undergraduate student Vishal Satish, dramatically sped up the computing time of the motion planner by integrating a deep learning neural network.\n",
            "\n",
            "Neural networks allow a robot to learn from examples. Later, the robot can often generalize to similar objects and motions.\n",
            "\n",
            "However, these approximations aren't always accurate enough. Goldberg and Ichnowski found that the approximation generated by the neural network could then be optimized using the motion planner.\n",
            "\n",
            "\"The neural network takes only a few milliseconds to compute an approximate motion. It's very fast, but it's inaccurate,\" Ichnowski said. \"However, if we then feed that approximation into the motion planner, the motion planner only needs a few iterations to compute the final motion.\"\n",
            "\n",
            "By combining the neural network with the motion planner, the team cut average computation time from 29 seconds to 80 milliseconds, or less than one-tenth of a second.\n",
            "\n",
            "Goldberg predicts that, with this and other advances in robotic technology, robots could be assisting in warehouse environments in the next few years.\n",
            "\n",
            "\"Shopping for groceries, pharmaceuticals, clothing and many other things has changed as a result of COVID-19, and people are probably going to continue shopping this way even after the pandemic is over,\" Goldberg said. \"This is an exciting new opportunity for robots to support human workers.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAQGLJER-M_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0edb0a8c-bc77-4dde-9d82-3e229b088151"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICOgq6g6zZic"
      },
      "source": [
        "Print the total number of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zew79xxcyv4Y",
        "outputId": "9d635cee-3299-466b-99fb-200945f442c6"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "c = sent_tokenize(d)\n",
        "print(len(c))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR8vnVc5-thQ"
      },
      "source": [
        "Dividing into 5 documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9v-NvDGyv2u",
        "outputId": "571f5978-282a-47f1-f7f3-7953f6a83a0f"
      },
      "source": [
        "D1 = c[:5]\n",
        "D2 = c[5:10]\n",
        "D3 = c[10:15]\n",
        "D4 = c[15:20]\n",
        "D5 = c[20:26]\n",
        "print(len(D1),len(D2),len(D3),len(D4),len(D5))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 5 5 5 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwdFB7ATz4-i"
      },
      "source": [
        "D1 = \"\".join(D1)\n",
        "D2 = \"\".join(D2)\n",
        "D3 = \"\".join(D3)\n",
        "D4 = \"\".join(D4)\n",
        "D5 = \"\".join(D5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZKTwiDiz_xl"
      },
      "source": [
        "To select only AlphaNumeric characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRmajZuSz9P9"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "d1 =  tokenizer.tokenize(D1)\n",
        "d2 =  tokenizer.tokenize(D2)\n",
        "d3 =  tokenizer.tokenize(D3)\n",
        "d4 =  tokenizer.tokenize(D4)\n",
        "d5 =  tokenizer.tokenize(D5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efEgF0xN0KZ7"
      },
      "source": [
        "Calculating TF (Term Frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naYXuSz-0OGi"
      },
      "source": [
        "d1, d2, d3, d4, d5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLK1nym6z9SY",
        "outputId": "37fb9d13-5028-4096-e948-4f73b5b77468"
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "fd1 = FreqDist(d1)\n",
        "print(fd1.most_common(len(d1)),\"\\n\")\n",
        "fd2 = FreqDist(d2)\n",
        "print(fd2.most_common(len(d2)),\"\\n\")\n",
        "fd3 = FreqDist(d3)\n",
        "print(fd3.most_common(len(d3)),\"\\n\")\n",
        "fd4 = FreqDist(d4)\n",
        "print(fd4.most_common(len(d4)),\"\\n\")\n",
        "fd5 = FreqDist(d5)\n",
        "print(fd5.most_common(len(d5)),\"\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('and', 10), ('to', 10), ('the', 9), ('robots', 5), ('in', 5), ('warehouse', 5), ('move', 4), ('objects', 4), ('of', 4), ('grasp', 3), ('software', 3), ('gives', 3), ('speed', 3), ('skill', 3), ('assist', 3), ('environments', 3), ('have', 3), ('that', 3), ('for', 3), ('humans', 3), ('with', 2), ('18', 2), ('University', 2), ('California', 2), ('Berkeley', 2), ('Researchers', 2), ('created', 2), ('new', 2), ('artificial', 2), ('intelligence', 2), ('smoothly', 2), ('making', 2), ('it', 2), ('feasible', 2), ('them', 2), ('soon', 2), ('safety', 2), ('online', 2), ('is', 2), ('many', 2), ('Deep', 1), ('learning', 1), ('helps', 1), ('ease', 1), ('Combining', 1), ('neural', 1), ('networks', 1), ('motion', 1), ('planning', 1), ('Date', 1), ('November', 1), ('2020', 1), ('Source', 1), ('Summary', 1), ('FULL', 1), ('STORY', 1), ('In', 1), ('past', 1), ('year', 1), ('lockdowns', 1), ('other', 1), ('COVID', 1), ('19', 1), ('measures', 1), ('made', 1), ('shopping', 1), ('more', 1), ('popular', 1), ('than', 1), ('ever', 1), ('but', 1), ('skyrocketing', 1), ('demand', 1), ('leaving', 1), ('retailers', 1), ('struggling', 1), ('fulfill', 1), ('orders', 1), ('while', 1), ('ensuring', 1), ('their', 1), ('employees', 1), ('at', 1), ('The', 1), ('technology', 1), ('described', 1), ('a', 1), ('paper', 1), ('published', 1), ('today', 1), ('Wednesday', 1), ('Nov', 1), ('journal', 1), ('Science', 1), ('Robotics', 1), ('Automating', 1), ('tasks', 1), ('can', 1), ('be', 1), ('challenging', 1), ('because', 1), ('actions', 1), ('come', 1), ('naturally', 1), ('like', 1), ('deciding', 1), ('where', 1), ('how', 1), ('pick', 1), ('up', 1), ('different', 1), ('types', 1), ('then', 1), ('coordinating', 1), ('shoulder', 1), ('arm', 1), ('wrist', 1), ('movements', 1), ('needed', 1), ('each', 1), ('object', 1), ('from', 1), ('one', 1), ('location', 1), ('another', 1), ('are', 1), ('actually', 1), ('quite', 1), ('difficult', 1)] \n",
            "\n",
            "[('the', 5), ('and', 3), ('motion', 2), ('to', 2), ('be', 2), ('can', 2), ('of', 2), ('robots', 2), ('still', 2), ('it', 2), ('different', 2), ('in', 2), ('is', 2), ('over', 2), ('Robotic', 1), ('also', 1), ('tends', 1), ('jerky', 1), ('which', 1), ('increase', 1), ('risk', 1), ('damaging', 1), ('both', 1), ('products', 1), ('Warehouses', 1), ('are', 1), ('operated', 1), ('primarily', 1), ('by', 1), ('humans', 1), ('because', 1), ('s', 1), ('very', 1), ('hard', 1), ('for', 1), ('reliably', 1), ('grasp', 1), ('many', 1), ('objects', 1), ('said', 1), ('Ken', 1), ('Goldberg', 1), ('William', 1), ('S', 1), ('Floyd', 1), ('Jr', 1), ('Distinguished', 1), ('Chair', 1), ('Engineering', 1), ('at', 1), ('UC', 1), ('Berkeley', 1), ('senior', 1), ('author', 1), ('study', 1), ('In', 1), ('an', 1), ('automobile', 1), ('assembly', 1), ('line', 1), ('same', 1), ('repeated', 1), ('again', 1), ('so', 1), ('that', 1), ('automated', 1), ('But', 1), ('a', 1), ('warehouse', 1), ('every', 1), ('order', 1)] \n",
            "\n",
            "[('the', 7), ('a', 5), ('to', 5), ('and', 4), ('of', 3), ('In', 2), ('Goldberg', 2), ('UC', 2), ('Berkeley', 2), ('Ichnowski', 2), ('could', 2), ('compute', 2), ('how', 2), ('robot', 2), ('should', 2), ('up', 2), ('an', 2), ('object', 2), ('from', 2), ('motions', 2), ('by', 2), ('planner', 2), ('student', 2), ('earlier', 1), ('work', 1), ('postdoctoral', 1), ('researcher', 1), ('Jeffrey', 1), ('created', 1), ('Grasp', 1), ('Optimized', 1), ('Motion', 1), ('Planner', 1), ('that', 1), ('both', 1), ('pick', 1), ('it', 1), ('move', 1), ('transfer', 1), ('one', 1), ('location', 1), ('another', 1), ('However', 1), ('generated', 1), ('this', 1), ('were', 1), ('jerky', 1), ('While', 1), ('parameters', 1), ('software', 1), ('be', 1), ('tweaked', 1), ('generate', 1), ('smoother', 1), ('these', 1), ('calculations', 1), ('took', 1), ('average', 1), ('about', 1), ('half', 1), ('minute', 1), ('new', 1), ('study', 1), ('in', 1), ('collaboration', 1), ('with', 1), ('graduate', 1), ('Yahav', 1), ('Avigal', 1), ('undergraduate', 1), ('Vishal', 1), ('Satish', 1), ('dramatically', 1), ('sped', 1), ('computing', 1), ('time', 1), ('motion', 1), ('integrating', 1), ('deep', 1), ('learning', 1), ('neural', 1), ('network', 1), ('Neural', 1), ('networks', 1), ('allow', 1), ('learn', 1), ('examples', 1)] \n",
            "\n",
            "[('the', 4), ('to', 2), ('and', 2), ('Ichnowski', 2), ('neural', 2), ('network', 2), ('motion', 2), ('s', 2), ('Later', 1), ('robot', 1), ('can', 1), ('often', 1), ('generalize', 1), ('similar', 1), ('objects', 1), ('motions', 1), ('However', 1), ('these', 1), ('approximations', 1), ('aren', 1), ('t', 1), ('always', 1), ('accurate', 1), ('enough', 1), ('Goldberg', 1), ('found', 1), ('that', 1), ('approximation', 1), ('generated', 1), ('by', 1), ('could', 1), ('then', 1), ('be', 1), ('optimized', 1), ('using', 1), ('planner', 1), ('The', 1), ('takes', 1), ('only', 1), ('a', 1), ('few', 1), ('milliseconds', 1), ('compute', 1), ('an', 1), ('approximate', 1), ('It', 1), ('very', 1), ('fast', 1), ('but', 1), ('it', 1), ('inaccurate', 1), ('said', 1)] \n",
            "\n",
            "[('the', 8), ('motion', 4), ('to', 4), ('planner', 3), ('a', 3), ('and', 3), ('in', 3), ('that', 2), ('few', 2), ('with', 2), ('of', 2), ('Goldberg', 2), ('this', 2), ('other', 2), ('robots', 2), ('for', 2), ('is', 2), ('However', 1), ('if', 1), ('we', 1), ('then', 1), ('feed', 1), ('approximation', 1), ('into', 1), ('only', 1), ('needs', 1), ('iterations', 1), ('compute', 1), ('final', 1), ('By', 1), ('combining', 1), ('neural', 1), ('network', 1), ('team', 1), ('cut', 1), ('average', 1), ('computation', 1), ('time', 1), ('from', 1), ('29', 1), ('seconds', 1), ('80', 1), ('milliseconds', 1), ('or', 1), ('less', 1), ('than', 1), ('one', 1), ('tenth', 1), ('second', 1), ('predicts', 1), ('advances', 1), ('robotic', 1), ('technology', 1), ('could', 1), ('be', 1), ('assisting', 1), ('warehouse', 1), ('environments', 1), ('next', 1), ('years', 1), ('Shopping', 1), ('groceries', 1), ('pharmaceuticals', 1), ('clothing', 1), ('many', 1), ('things', 1), ('has', 1), ('changed', 1), ('as', 1), ('result', 1), ('COVID', 1), ('19', 1), ('people', 1), ('are', 1), ('probably', 1), ('going', 1), ('continue', 1), ('shopping', 1), ('way', 1), ('even', 1), ('after', 1), ('pandemic', 1), ('over', 1), ('said', 1), ('This', 1), ('an', 1), ('exciting', 1), ('new', 1), ('opportunity', 1), ('support', 1), ('human', 1), ('workers', 1)] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S2I_SY-0WYG"
      },
      "source": [
        "Using Tf-Idf Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKPHsXex4NUH"
      },
      "source": [
        "**TF-IDF stands for “Term Frequency — Inverse Document Frequency”**. \n",
        "\n",
        "This is a technique to quantify a word in documents, we generally compute a weight to each word which signifies the importance of the word in the document and corpus. This method is a widely used technique in Information Retrieval and Text Mining.\n",
        "\n",
        "TF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)\n",
        "\n",
        "Terminology\n",
        "\n",
        "t — term (word)\n",
        "\n",
        "d — document (set of words)\n",
        "\n",
        "N — count of corpus\n",
        "\n",
        "corpus — the total document set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qkVoU6W4m26"
      },
      "source": [
        "tf(t,d) = count of t in d / number of words in d\n",
        "\n",
        "df(t) = occurrence of t in documents\n",
        "\n",
        "idf(t) = N/df\n",
        "\n",
        "idf(t) = log(N/(df + 1))\n",
        "\n",
        "tf-idf(t, d) = tf(t, d) * log(N/(df + 1))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2BWgmiaH48q"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPSl1qNs0R3Y"
      },
      "source": [
        "corpus = [D1, D2, D3, D4, D5]\n",
        "X = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0_BdEoh0fgn",
        "outputId": "a55b41ad-fd55-44f8-b271-73411533f805"
      },
      "source": [
        "feat = vectorizer.get_feature_names()\n",
        "feat.reverse()\n",
        "feat"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['years',\n",
              " 'year',\n",
              " 'yahav',\n",
              " 'wrist',\n",
              " 'workers',\n",
              " 'work',\n",
              " 'with',\n",
              " 'william',\n",
              " 'while',\n",
              " 'which',\n",
              " 'where',\n",
              " 'were',\n",
              " 'wednesday',\n",
              " 'we',\n",
              " 'way',\n",
              " 'warehouses',\n",
              " 'warehouse',\n",
              " 'vishal',\n",
              " 'very',\n",
              " 'using',\n",
              " 'up',\n",
              " 'university',\n",
              " 'undergraduate',\n",
              " 'uc',\n",
              " 'types',\n",
              " 'tweaked',\n",
              " 'transfer',\n",
              " 'took',\n",
              " 'today',\n",
              " 'to',\n",
              " 'time',\n",
              " 'this',\n",
              " 'things',\n",
              " 'these',\n",
              " 'then',\n",
              " 'them',\n",
              " 'their',\n",
              " 'the',\n",
              " 'that',\n",
              " 'than',\n",
              " 'tenth',\n",
              " 'tends',\n",
              " 'technology',\n",
              " 'team',\n",
              " 'tasks',\n",
              " 'takes',\n",
              " 'support',\n",
              " 'summary',\n",
              " 'study',\n",
              " 'student',\n",
              " 'struggling',\n",
              " 'story',\n",
              " 'still',\n",
              " 'speed',\n",
              " 'sped',\n",
              " 'source',\n",
              " 'soon',\n",
              " 'software',\n",
              " 'so',\n",
              " 'smoothly',\n",
              " 'smoother',\n",
              " 'skyrocketing',\n",
              " 'skill',\n",
              " 'similar',\n",
              " 'shoulder',\n",
              " 'should',\n",
              " 'shopping',\n",
              " 'senior',\n",
              " 'seconds',\n",
              " 'second',\n",
              " 'science',\n",
              " 'satish',\n",
              " 'same',\n",
              " 'said',\n",
              " 'safety',\n",
              " 'robots',\n",
              " 'robotics',\n",
              " 'robotic',\n",
              " 'robot',\n",
              " 'risk',\n",
              " 'retailers',\n",
              " 'result',\n",
              " 'researchers',\n",
              " 'researcher',\n",
              " 'repeated',\n",
              " 'reliably',\n",
              " 'quite',\n",
              " 'published',\n",
              " 'products',\n",
              " 'probably',\n",
              " 'primarily',\n",
              " 'predicts',\n",
              " 'postdoctoral',\n",
              " 'popular',\n",
              " 'planning',\n",
              " 'planner',\n",
              " 'pick',\n",
              " 'pharmaceuticals',\n",
              " 'people',\n",
              " 'past',\n",
              " 'parameters',\n",
              " 'paper',\n",
              " 'pandemic',\n",
              " 'over',\n",
              " 'other',\n",
              " 'orders',\n",
              " 'order',\n",
              " 'or',\n",
              " 'optimized',\n",
              " 'opportunity',\n",
              " 'operated',\n",
              " 'only',\n",
              " 'online',\n",
              " 'one',\n",
              " 'often',\n",
              " 'of',\n",
              " 'objects',\n",
              " 'object',\n",
              " 'november',\n",
              " 'nov',\n",
              " 'next',\n",
              " 'new',\n",
              " 'neural',\n",
              " 'networks',\n",
              " 'network',\n",
              " 'needs',\n",
              " 'needed',\n",
              " 'naturally',\n",
              " 'movements',\n",
              " 'move',\n",
              " 'motions',\n",
              " 'motion',\n",
              " 'more',\n",
              " 'minute',\n",
              " 'milliseconds',\n",
              " 'measures',\n",
              " 'many',\n",
              " 'making',\n",
              " 'made',\n",
              " 'lockdowns',\n",
              " 'location',\n",
              " 'line',\n",
              " 'like',\n",
              " 'less',\n",
              " 'leaving',\n",
              " 'learning',\n",
              " 'learn',\n",
              " 'later',\n",
              " 'ken',\n",
              " 'jr',\n",
              " 'journal',\n",
              " 'jerky',\n",
              " 'jeffrey',\n",
              " 'iterations',\n",
              " 'it',\n",
              " 'is',\n",
              " 'into',\n",
              " 'intelligence',\n",
              " 'integrating',\n",
              " 'increase',\n",
              " 'inaccurate',\n",
              " 'in',\n",
              " 'if',\n",
              " 'ichnowski',\n",
              " 'humans',\n",
              " 'human',\n",
              " 'however',\n",
              " 'how',\n",
              " 'helps',\n",
              " 'have',\n",
              " 'has',\n",
              " 'hard',\n",
              " 'half',\n",
              " 'groceries',\n",
              " 'grasp',\n",
              " 'graduate',\n",
              " 'goldberg',\n",
              " 'going',\n",
              " 'gives',\n",
              " 'generated',\n",
              " 'generate',\n",
              " 'generalize',\n",
              " 'full',\n",
              " 'fulfill',\n",
              " 'from',\n",
              " 'found',\n",
              " 'for',\n",
              " 'floyd',\n",
              " 'final',\n",
              " 'few',\n",
              " 'feed',\n",
              " 'feasible',\n",
              " 'fast',\n",
              " 'exciting',\n",
              " 'examples',\n",
              " 'every',\n",
              " 'ever',\n",
              " 'even',\n",
              " 'environments',\n",
              " 'ensuring',\n",
              " 'enough',\n",
              " 'engineering',\n",
              " 'employees',\n",
              " 'ease',\n",
              " 'earlier',\n",
              " 'each',\n",
              " 'dramatically',\n",
              " 'distinguished',\n",
              " 'difficult',\n",
              " 'different',\n",
              " 'described',\n",
              " 'demand',\n",
              " 'deep',\n",
              " 'deciding',\n",
              " 'date',\n",
              " 'damaging',\n",
              " 'cut',\n",
              " 'created',\n",
              " 'covid',\n",
              " 'could',\n",
              " 'coordinating',\n",
              " 'continue',\n",
              " 'computing',\n",
              " 'compute',\n",
              " 'computation',\n",
              " 'come',\n",
              " 'combining',\n",
              " 'collaboration',\n",
              " 'clothing',\n",
              " 'changed',\n",
              " 'challenging',\n",
              " 'chair',\n",
              " 'can',\n",
              " 'california',\n",
              " 'calculations',\n",
              " 'by',\n",
              " 'but',\n",
              " 'both',\n",
              " 'berkeley',\n",
              " 'because',\n",
              " 'be',\n",
              " 'avigal',\n",
              " 'average',\n",
              " 'automobile',\n",
              " 'automating',\n",
              " 'automated',\n",
              " 'author',\n",
              " 'at',\n",
              " 'assisting',\n",
              " 'assist',\n",
              " 'assembly',\n",
              " 'as',\n",
              " 'artificial',\n",
              " 'arm',\n",
              " 'aren',\n",
              " 'are',\n",
              " 'approximations',\n",
              " 'approximation',\n",
              " 'approximate',\n",
              " 'another',\n",
              " 'and',\n",
              " 'an',\n",
              " 'always',\n",
              " 'also',\n",
              " 'allow',\n",
              " 'again',\n",
              " 'after',\n",
              " 'advances',\n",
              " 'actually',\n",
              " 'actions',\n",
              " 'accurate',\n",
              " 'about',\n",
              " '80',\n",
              " '29',\n",
              " '2020',\n",
              " '19',\n",
              " '18']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjFFFeUg0iKh",
        "outputId": "024a7e42-50aa-4278-c8f7-7d6232a16132"
      },
      "source": [
        "len(feat)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feXst4FD0qno"
      },
      "source": [
        "x1, x2, x3, x4, x5 = X[0], X[1], X[2], X[3], X[4]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLGC7dG40uAA"
      },
      "source": [
        "mat = [x1, x2, x3, x4, x5]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayYSg_0Y6vtF"
      },
      "source": [
        "**sklearn.metrics.pairwise.cosine_similarity**\n",
        "\n",
        "sklearn.metrics.pairwise.cosine_similarity(X, Y=None, dense_output=True)[source]\n",
        "Compute cosine similarity between samples in X and Y.\n",
        "\n",
        "Cosine similarity, or the cosine kernel, computes similarity as the normalized dot product of X and Y:\n",
        "\n",
        "K(X, Y) = <X, Y> / (||X||*||Y||)\n",
        "\n",
        "On L2-normalized data, this function is equivalent to linear_kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwVUfuIs0uCl"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEwsgOk90zzg",
        "outputId": "7569b4d6-a57f-4f79-bcd6-660a9faf64d7"
      },
      "source": [
        "res = {}\n",
        "for i in range(len(mat)):\n",
        "    for j in range(len(mat)):\n",
        "        if i!=j:\n",
        "            ans = cosine_similarity(mat[i], mat[j])\n",
        "            res[i+1, j+1] = ans[0][0]    \n",
        "            print('Doc {0} & {1} = {2}'.format(i+1, j+1, ans))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doc 1 & 2 = [[0.35236025]]\n",
            "Doc 1 & 3 = [[0.35100404]]\n",
            "Doc 1 & 4 = [[0.22528953]]\n",
            "Doc 1 & 5 = [[0.35694599]]\n",
            "Doc 2 & 1 = [[0.35236025]]\n",
            "Doc 2 & 3 = [[0.28896102]]\n",
            "Doc 2 & 4 = [[0.26459833]]\n",
            "Doc 2 & 5 = [[0.32357256]]\n",
            "Doc 3 & 1 = [[0.35100404]]\n",
            "Doc 3 & 2 = [[0.28896102]]\n",
            "Doc 3 & 4 = [[0.41297406]]\n",
            "Doc 3 & 5 = [[0.37722553]]\n",
            "Doc 4 & 1 = [[0.22528953]]\n",
            "Doc 4 & 2 = [[0.26459833]]\n",
            "Doc 4 & 3 = [[0.41297406]]\n",
            "Doc 4 & 5 = [[0.35292688]]\n",
            "Doc 5 & 1 = [[0.35694599]]\n",
            "Doc 5 & 2 = [[0.32357256]]\n",
            "Doc 5 & 3 = [[0.37722553]]\n",
            "Doc 5 & 4 = [[0.35292688]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARJ6zvdk02bW",
        "outputId": "2da48f2b-182f-4424-9c64-fb9f72b158e0"
      },
      "source": [
        "res"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(1, 2): 0.3523602543112174,\n",
              " (1, 3): 0.3510040353026286,\n",
              " (1, 4): 0.225289526571758,\n",
              " (1, 5): 0.3569459861998385,\n",
              " (2, 1): 0.3523602543112174,\n",
              " (2, 3): 0.2889610165480311,\n",
              " (2, 4): 0.2645983319517201,\n",
              " (2, 5): 0.32357255567680865,\n",
              " (3, 1): 0.3510040353026286,\n",
              " (3, 2): 0.2889610165480311,\n",
              " (3, 4): 0.4129740611811327,\n",
              " (3, 5): 0.3772255258928608,\n",
              " (4, 1): 0.225289526571758,\n",
              " (4, 2): 0.2645983319517201,\n",
              " (4, 3): 0.4129740611811327,\n",
              " (4, 5): 0.3529268792212952,\n",
              " (5, 1): 0.3569459861998385,\n",
              " (5, 2): 0.32357255567680865,\n",
              " (5, 3): 0.3772255258928608,\n",
              " (5, 4): 0.3529268792212952}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EjP06-I05ae"
      },
      "source": [
        "maxi = list(res.keys())[list(res.values()).index(max(res.values()))]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NrusrPp66Fa"
      },
      "source": [
        "Displaying maximum cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaPZEjWc0-cB",
        "outputId": "1ac65350-c7be-4979-95c3-f24cd612671a"
      },
      "source": [
        "print('Documents with maximum cosine similarity are {0} & {1}'.format(maxi[0], maxi[1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Documents with maximum cosine similarity are 3 & 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}