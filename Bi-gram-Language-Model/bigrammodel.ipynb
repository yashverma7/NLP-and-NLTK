{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bigrammodel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyWvvlY4AiWP",
        "colab_type": "text"
      },
      "source": [
        "What is a Language Model in NLP?\n",
        "\n",
        "Building an N-gram Language Model\n",
        "\n",
        "Building a Neural Language Model\n",
        "\n",
        "Natural Language Generation using OpenAIâ€™s GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GcGcRGP5Lbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "20b730a3-784c-4a8a-aeb0-ef5d5ef26cda"
      },
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Create a placeholder for model\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of co-occurance  \n",
        "for sentence in reuters.sents():\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        " \n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-XloNuC51Wn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "082a881b-cb77-4a95-9214-76ef5f76e6ed"
      },
      "source": [
        "#predict the next word\n",
        "dict(model[\"today\",\"the\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bank': 0.05555555555555555,\n",
              " 'European': 0.05555555555555555,\n",
              " 'Higher': 0.05555555555555555,\n",
              " 'Italian': 0.05555555555555555,\n",
              " 'Turkish': 0.05555555555555555,\n",
              " 'company': 0.16666666666666666,\n",
              " 'emirate': 0.05555555555555555,\n",
              " 'increase': 0.05555555555555555,\n",
              " 'newspaper': 0.05555555555555555,\n",
              " 'options': 0.05555555555555555,\n",
              " 'overseas': 0.05555555555555555,\n",
              " 'pound': 0.05555555555555555,\n",
              " 'price': 0.1111111111111111,\n",
              " 'public': 0.05555555555555555,\n",
              " 'time': 0.05555555555555555}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slh6R8Jo6FcN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab2104c7-07d4-41fe-c621-e8db550b0116"
      },
      "source": [
        "#predict the next word\n",
        "dict(model[\"the\",\"price\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(': 0.009302325581395349,\n",
              " ',': 0.018604651162790697,\n",
              " ',\"': 0.004651162790697674,\n",
              " '-': 0.004651162790697674,\n",
              " '.': 0.023255813953488372,\n",
              " 'Royal': 0.004651162790697674,\n",
              " 'action': 0.004651162790697674,\n",
              " 'adjustment': 0.023255813953488372,\n",
              " 'adjustments': 0.004651162790697674,\n",
              " 'again': 0.004651162790697674,\n",
              " 'and': 0.004651162790697674,\n",
              " 'approached': 0.004651162790697674,\n",
              " 'at': 0.023255813953488372,\n",
              " 'base': 0.004651162790697674,\n",
              " 'being': 0.004651162790697674,\n",
              " 'changes': 0.004651162790697674,\n",
              " 'climate': 0.004651162790697674,\n",
              " 'collapse': 0.004651162790697674,\n",
              " 'could': 0.004651162790697674,\n",
              " 'cut': 0.009302325581395349,\n",
              " 'cuts': 0.009302325581395349,\n",
              " 'difference': 0.004651162790697674,\n",
              " 'differentials': 0.009302325581395349,\n",
              " 'drop': 0.004651162790697674,\n",
              " 'effect': 0.004651162790697674,\n",
              " 'evolution': 0.004651162790697674,\n",
              " 'factor': 0.004651162790697674,\n",
              " 'fall': 0.004651162790697674,\n",
              " 'for': 0.05116279069767442,\n",
              " 'freeze': 0.009302325581395349,\n",
              " 'from': 0.004651162790697674,\n",
              " 'gap': 0.004651162790697674,\n",
              " 'guaranteed': 0.004651162790697674,\n",
              " 'had': 0.004651162790697674,\n",
              " 'has': 0.009302325581395349,\n",
              " 'hike': 0.004651162790697674,\n",
              " 'holds': 0.004651162790697674,\n",
              " 'in': 0.004651162790697674,\n",
              " 'increase': 0.009302325581395349,\n",
              " 'increases': 0.013953488372093023,\n",
              " 'instability': 0.004651162790697674,\n",
              " 'is': 0.018604651162790697,\n",
              " 'it': 0.05581395348837209,\n",
              " 'led': 0.004651162790697674,\n",
              " 'limit': 0.004651162790697674,\n",
              " 'move': 0.004651162790697674,\n",
              " 'moved': 0.004651162790697674,\n",
              " 'now': 0.004651162790697674,\n",
              " 'of': 0.3209302325581395,\n",
              " 'on': 0.004651162790697674,\n",
              " 'outlook': 0.004651162790697674,\n",
              " 'paid': 0.013953488372093023,\n",
              " 'per': 0.013953488372093023,\n",
              " 'policy': 0.004651162790697674,\n",
              " 'projected': 0.004651162790697674,\n",
              " 'raise': 0.004651162790697674,\n",
              " 'reductions': 0.004651162790697674,\n",
              " 'related': 0.004651162790697674,\n",
              " 'review': 0.004651162790697674,\n",
              " 'revision': 0.004651162790697674,\n",
              " 'rises': 0.004651162790697674,\n",
              " 'slump': 0.004651162790697674,\n",
              " 'slumped': 0.004651162790697674,\n",
              " 'stayed': 0.009302325581395349,\n",
              " 'structure': 0.004651162790697674,\n",
              " 'support': 0.004651162790697674,\n",
              " 'the': 0.013953488372093023,\n",
              " 'to': 0.05581395348837209,\n",
              " 'used': 0.004651162790697674,\n",
              " 'was': 0.009302325581395349,\n",
              " 'we': 0.004651162790697674,\n",
              " 'went': 0.004651162790697674,\n",
              " 'while': 0.004651162790697674,\n",
              " 'will': 0.013953488372093023,\n",
              " 'would': 0.009302325581395349,\n",
              " 'yesterday': 0.004651162790697674,\n",
              " 'zone': 0.004651162790697674}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxTS-Qzd8oig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9ea90cec-8b6b-4866-e160-281b83146922"
      },
      "source": [
        "from nltk.corpus import reuters\n",
        "from collections import Counter\n",
        " \n",
        " \n",
        "counts = Counter(reuters.words())\n",
        "total_count = len(reuters.words())\n",
        " \n",
        "# The most common 20 words are ...\n",
        "print (counts.most_common(n=20))\n",
        "# [(u'.', 94687), (u',', 72360), (u'the', 58251), (u'of', 35979), (u'to', 34035), (u'in', 26478), (u'said', 25224), (u'and', 25043), (u'a', 23492), (u'mln', 18037), (u'vs', 14120), (u'-', 13705), (u'for', 12785), (u'dlrs', 11730), (u\"'\", 11272), (u'The', 10968), (u'000', 10277), (u'1', 9977), (u's', 9298), (u'pct', 9093)]\n",
        " \n",
        "# Compute the frequencies\n",
        "for word in counts:\n",
        "    counts[word] /= float(total_count)\n",
        " \n",
        "# The frequencies should add up to 1\n",
        "print (sum(counts.values()))  # 1.0\n",
        " \n",
        "import random\n",
        " \n",
        "# Generate 100 words of language\n",
        "text = []\n",
        " \n",
        "for _ in range(100):\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        " \n",
        "    for word, freq in counts.items():\n",
        "        accumulator += freq\n",
        " \n",
        "        if accumulator >= r:\n",
        "            text.append(word)\n",
        "            break\n",
        " \n",
        "print (' '.join(text))\n",
        "# tax been its and industrial and vote \" decision rates elimination and 2 . base Ltd one merger half three division trading it to company before CES mln may to . . , and U is - exclusive affiliate - biggest its Association sides above two nearby NOTES 4TH prepared term areas growth said to each gold policy 0 PLOUGH kind economy director currencies requiring . ' loan growth , 83 . new The target Refining 114 STAKE the it on . to ; measure deposit Corp Emergency on 63 the reported the TREASURY state EC to Grosso as basius"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('.', 94687), (',', 72360), ('the', 58251), ('of', 35979), ('to', 34035), ('in', 26478), ('said', 25224), ('and', 25043), ('a', 23492), ('mln', 18037), ('vs', 14120), ('-', 13705), ('for', 12785), ('dlrs', 11730), (\"'\", 11272), ('The', 10968), ('000', 10277), ('1', 9977), ('s', 9298), ('pct', 9093)]\n",
            "1.0000000000006808\n",
            ". pre 21 a National foreign will SECURITY they said early Nine buy announcement General 41 by . , Ttl ; percentage . probably a any 3 shares 000 more results figures all is RBD a 0 REVERSE to 1 meeting options 68 plant year to all Data 16 deficiency of , Sisters processing had - There newly to to Commission restaurants of A , of rules Savings two has 6 usually said eight , 7 out foreign 7 of a a Paris the Judge 1990 1 , . , would would vs figures Erbynn ( , share 4 vs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocydHI0r8otk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "baf0d77a-ebfe-4d00-f085-1bce344a5f01"
      },
      "source": [
        "from functools import reduce\n",
        "# The probability of a text\n",
        "from operator import mul\n",
        "print (reduce(mul, [counts[w] for w in text], 1.0)) # 3.0290546883e-32"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.117958952224002e-293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfJcVGaL-PVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b7b9208f-11ee-4030-bf6d-22eb023ea617"
      },
      "source": [
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        " \n",
        "first_sentence = reuters.sents()[0]\n",
        "print (first_sentence) # [u'ASIAN', u'EXPORTERS', u'FEAR', u'DAMAGE', u'FROM' ...\n",
        " \n",
        "# Get the bigrams\n",
        "print (list(bigrams(first_sentence))) # [(u'ASIAN', u'EXPORTERS'), (u'EXPORTERS', u'FEAR'), (u'FEAR', u'DAMAGE'), (u'DAMAGE', u'FROM'), ...\n",
        " \n",
        "# Get the padded bigrams\n",
        "print (list(bigrams(first_sentence, pad_left=True, pad_right=True))) # [(None, u'ASIAN'), (u'ASIAN', u'EXPORTERS'), (u'EXPORTERS', u'FEAR'), (u'FEAR', u'DAMAGE'), (u'DAMAGE', u'FROM'),\n",
        " \n",
        "# Get the trigrams\n",
        "print (list(trigrams(first_sentence))) # [(u'ASIAN', u'EXPORTERS', u'FEAR'), (u'EXPORTERS', u'FEAR', u'DAMAGE'), (u'FEAR', u'DAMAGE', u'FROM'), ...\n",
        " \n",
        "# Get the padded trigrams\n",
        "print (list(trigrams(first_sentence, pad_left=True, pad_right=True))) # [(None, None, u'ASIAN'), (None, u'ASIAN', u'EXPORTERS'), (u'ASIAN', u'EXPORTERS', u'FEAR'), (u'EXPORTERS', u'FEAR', u'DAMAGE'), (u'FEAR', u'DAMAGE', u'FROM') ...\n",
        " \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n",
            "[('ASIAN', 'EXPORTERS'), ('EXPORTERS', 'FEAR'), ('FEAR', 'DAMAGE'), ('DAMAGE', 'FROM'), ('FROM', 'U'), ('U', '.'), ('.', 'S'), ('S', '.-'), ('.-', 'JAPAN'), ('JAPAN', 'RIFT'), ('RIFT', 'Mounting'), ('Mounting', 'trade'), ('trade', 'friction'), ('friction', 'between'), ('between', 'the'), ('the', 'U'), ('U', '.'), ('.', 'S'), ('S', '.'), ('.', 'And'), ('And', 'Japan'), ('Japan', 'has'), ('has', 'raised'), ('raised', 'fears'), ('fears', 'among'), ('among', 'many'), ('many', 'of'), ('of', 'Asia'), ('Asia', \"'\"), (\"'\", 's'), ('s', 'exporting'), ('exporting', 'nations'), ('nations', 'that'), ('that', 'the'), ('the', 'row'), ('row', 'could'), ('could', 'inflict'), ('inflict', 'far'), ('far', '-'), ('-', 'reaching'), ('reaching', 'economic'), ('economic', 'damage'), ('damage', ','), (',', 'businessmen'), ('businessmen', 'and'), ('and', 'officials'), ('officials', 'said'), ('said', '.')]\n",
            "[(None, 'ASIAN'), ('ASIAN', 'EXPORTERS'), ('EXPORTERS', 'FEAR'), ('FEAR', 'DAMAGE'), ('DAMAGE', 'FROM'), ('FROM', 'U'), ('U', '.'), ('.', 'S'), ('S', '.-'), ('.-', 'JAPAN'), ('JAPAN', 'RIFT'), ('RIFT', 'Mounting'), ('Mounting', 'trade'), ('trade', 'friction'), ('friction', 'between'), ('between', 'the'), ('the', 'U'), ('U', '.'), ('.', 'S'), ('S', '.'), ('.', 'And'), ('And', 'Japan'), ('Japan', 'has'), ('has', 'raised'), ('raised', 'fears'), ('fears', 'among'), ('among', 'many'), ('many', 'of'), ('of', 'Asia'), ('Asia', \"'\"), (\"'\", 's'), ('s', 'exporting'), ('exporting', 'nations'), ('nations', 'that'), ('that', 'the'), ('the', 'row'), ('row', 'could'), ('could', 'inflict'), ('inflict', 'far'), ('far', '-'), ('-', 'reaching'), ('reaching', 'economic'), ('economic', 'damage'), ('damage', ','), (',', 'businessmen'), ('businessmen', 'and'), ('and', 'officials'), ('officials', 'said'), ('said', '.'), ('.', None)]\n",
            "[('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.')]\n",
            "[(None, None, 'ASIAN'), (None, 'ASIAN', 'EXPORTERS'), ('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.'), ('said', '.', None), ('.', None, None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFUaCYTU-PaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "21c59bf3-6c3c-49fe-af1e-cfa1d43fee25"
      },
      "source": [
        "\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        " \n",
        "for sentence in reuters.sents():\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        " \n",
        " \n",
        "print (model[\"what\", \"the\"][\"economists\"]) # \"economists\" follows \"what the\" 2 times\n",
        "print (model[\"what\", \"the\"][\"nonexistingword\"]) # 0 times\n",
        "print (model[None, None][\"The\"]) # 8839 sentences start with \"The\"\n",
        " \n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count\n",
        " \n",
        "print (model[\"what\", \"the\"][\"economists\"]) # 0.0434782608696\n",
        "print (model[\"what\", \"the\"][\"nonexistingword\"]) # 0.0\n",
        "print (model[None, None][\"The\"]) # 0.161543241465\n",
        " "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "0\n",
            "8839\n",
            "0.043478260869565216\n",
            "0.0\n",
            "0.16154324146501936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_qnJRm-hYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f358b61a-01e9-4d40-8407-4e9c89d4dc0e"
      },
      "source": [
        "\n",
        "import random\n",
        " \n",
        " \n",
        "text = [None, None]\n",
        " \n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        " \n",
        "    for word in model[tuple(text[-2:])].keys():\n",
        "        accumulator += model[tuple(text[-2:])][word]\n",
        " \n",
        "        if accumulator >= r:\n",
        "            text.append(word)\n",
        "            break\n",
        " \n",
        "    if text[-2:] == [None, None]:\n",
        "        sentence_finished = True\n",
        " \n",
        "print (' '.join([t for t in text if t]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\" A lot of ill feeling ,\" said Richardson Greenshields of Canada , France , Great Britain to join a hunger strike by 40 per cent , it said .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utYYlVVO_Wfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#On May 11 , 617 , 000 tonnes each , a Los Angeles , a subsidiary if it is being pressed by the mining equipment operations of 14 . \n",
        "#8 mln vs 112 , 000 Revs 7 , 624 , 208 tonnes in January 1986 , Allegheny said .\n",
        "\n",
        "#Britain ' s common shares at 25 . 0 pct .\n",
        "\n",
        "#The issue will probably be about 45 pct stake in CGCT .\n",
        "\n",
        "#In addition , its first agreement to acquire Atwell Fleming Printing Ltd , a senior dealer Eckhart Hager said .\n",
        "\n",
        "#Many local bankers argue the merger .\n",
        "\n",
        "#Total estimated paddy output was only for the sake of it was discontinuing talks with Washington .\n",
        "\n",
        "#Now that Tokyo has helped to keep cocoa off the Greek province of Camaguey , the Xerox affiliate that manufactures and markets are making threats ,\" one senior official said .\n",
        "\n",
        "#\" A lot of ill feeling ,\" said Richardson Greenshields of Canada , France , Great Britain to join a hunger strike by 40 per cent , it said ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzCuAlyj-hbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea6ea54a-a4c2-4abc-d34f-8abc00a85b83"
      },
      "source": [
        "import random\n",
        " \n",
        " \n",
        "text = [None, None]\n",
        "prob = 1.0  # <- Init probability\n",
        " \n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        " \n",
        "    for word in model[tuple(text[-2:])].keys():\n",
        "        accumulator += model[tuple(text[-2:])][word]\n",
        " \n",
        "        if accumulator >= r:\n",
        "            prob *= model[tuple(text[-2:])][word]  # <- Update the probability with the conditional probability of the new word\n",
        "            text.append(word)\n",
        "            break\n",
        " \n",
        "    if text[-2:] == [None, None]:\n",
        "        sentence_finished = True\n",
        " \n",
        "print (\"Probability of text=\", prob ) # <- Print the probability of the text\n",
        "print (' '.join([t for t in text if t]))\n",
        " \n",
        "# Probability of text= 4.69753034878e-48\n",
        "# DOW CHEMICAL & lt ; SFE > IN ACQUISITION TALKS Comdata Network Inc said it sold the unit , leading to the group and this would not resist a half mln barrels to 247 . 0 pct , Ivory Coast is the lowest growth rate , he said ."
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of text= 2.00546438439561e-11\n",
            "MARATHON RAISES CRUDE OIL POSTINGS 24 CANADIAN CTS / BBL , PAR GRADE TO RAISE USAIR STAKE TO PRIVATE INVESTORS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUWs9DuGAHEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_GALMSdID9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}