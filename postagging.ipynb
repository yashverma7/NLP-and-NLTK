{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "postagging",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nA9qWUqSjM5"
      },
      "source": [
        "#Categorizing and POS Tagging with NLTK Python\n",
        "Natural language processing is a sub-area of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (native) languages. This is nothing but how to program computers to process and analyze large amounts of natural language data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4HcTLpSSq5D"
      },
      "source": [
        "A part-of-speech tagger, or POS-tagger, processes a sequence of words and attaches a part of speech tag to each word. To do this first we have to use tokenization concept (Tokenization is the process by dividing the quantity of text into smaller parts called tokens.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW_2kjpcC8rp",
        "outputId": "2a7a7e19-f108-4288-b5fc-56c30459b27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "text = word_tokenize(\"Hello welcome to the world of to learn Categorizing and POS Tagging with NLTK and Python\")\n",
        "nltk.pos_tag(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hello', 'NNP'),\n",
              " ('welcome', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('world', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('to', 'TO'),\n",
              " ('learn', 'VB'),\n",
              " ('Categorizing', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('POS', 'NNP'),\n",
              " ('Tagging', 'NNP'),\n",
              " ('with', 'IN'),\n",
              " ('NLTK', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Python', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-jO4TpSzvZ"
      },
      "source": [
        "#Tagged Corpora\n",
        "Representing Tagged Tokens\n",
        "\n",
        "A tagged token is represented using a tuple consisting of the token and the tag. We can create one of these special tuples from the standard string representation of a tagged token, using the function str2tuple():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay_-pUC5FEYk",
        "outputId": "bac669b4-404a-4389-8e5d-4083dd6cfa4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tagged_token = nltk.tag.str2tuple('Learn/VB')\n",
        "tagged_token\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Learn', 'VB')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fXK1vsfFe-m",
        "outputId": "93fd757f-4544-42fe-e77f-8819c295089a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tagged_token[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Learn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA_tgIN-Fj2f",
        "outputId": "13081ce7-8d38-4f79-edc4-b4e3613ff9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tagged_token[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'VB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hswTqQerS-XQ"
      },
      "source": [
        "#Reading Tagged Corpora\n",
        "Several of the corpora included with NLTK have been tagged for their part-of-speech. \n",
        "\n",
        "Here’s an example of what you might see if you opened a file from the Brown Corpus with a text editor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG-imaZgFpTG",
        "outputId": "1b9a963e-181a-4564-cc16-771ec7d8dfe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.corpus.brown.tagged_words()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmFMrItdF8sy",
        "outputId": "6a749773-f031-49ec-c182-0f5c301b5f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nltk.corpus.brown.tagged_words(tagset='universal')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yy2h4QaTSBk"
      },
      "source": [
        "#Part of Speech Tagset\n",
        "Tagged corpora use many different conventions for tagging words.\n",
        "\n",
        "TagMeaningEnglish \n",
        "\n",
        "ExamplesADJadjectivenew, good, high, special, big, localADPadpositionon, of, at, with, by, into, underADVadverbreally, already, still, early, nowCONJconjunctionand, or, but, if, while, althoughDETdeterminer, articles, a, some, most, every, no, whichNOUNnounyear, home, costs, time, AfricaNUMnumeraltwenty-four, fourth, 1991, 14:24PRTparticleat, on, out, over per, that, up, withPRONpronounhe, their, her, its, my, I, usVERBverbis, say, told, given, playing, would. punctuation marks. ,;!Xotherersatz, esprit, dunno, gr8, university"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh4Dey_cF-xk",
        "outputId": "76a4532d-6fb5-4fe3-ae01-25c4948ac356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from nltk.corpus import brown\n",
        "brown_news_tagged = brown.tagged_words(categories='adventure', tagset='universal')\n",
        "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
        "tag_fd.most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NOUN', 13354),\n",
              " ('VERB', 12274),\n",
              " ('.', 10929),\n",
              " ('DET', 8155),\n",
              " ('ADP', 7069),\n",
              " ('PRON', 5205),\n",
              " ('ADV', 3879),\n",
              " ('ADJ', 3364),\n",
              " ('PRT', 2436),\n",
              " ('CONJ', 2173),\n",
              " ('NUM', 466),\n",
              " ('X', 38)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8l9Kp23TdwB"
      },
      "source": [
        "Nouns\n",
        "\n",
        "Nouns generally refer to people, places, things, or concepts, for example.: woman, Scotland, book, intelligence. The simplified noun tags are N for common nouns like a book, and NP for proper nouns like Scotland."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6GV9HNF-6R",
        "outputId": "68448aca-d1cd-432d-8b98-78caec17cd06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "word_tag_pairs = nltk.bigrams(brown_news_tagged)\n",
        "noun_preceders = [a[1] for (a, b) in word_tag_pairs if b[1] == 'NOUN']\n",
        "fdist = nltk.FreqDist(noun_preceders)\n",
        "[tag for (tag, _) in fdist.most_common()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'CONJ',\n",
              " 'NUM',\n",
              " 'ADV',\n",
              " 'PRON',\n",
              " 'PRT',\n",
              " 'X']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPgDUUKMO87H"
      },
      "source": [
        "POS Tagging\n",
        "\n",
        "Part-of-Speech or PoS tagging, then it may be defined as the process of assigning one of the parts of speech to\n",
        "the given word.\n",
        "\n",
        "The parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their\n",
        "sub-categories.\n",
        "\n",
        " NN stands for noun, NNP stands for proper noun, VB for verb and so on. For e.g. In \"Can you\n",
        "please buy me an Arizona tea\" , Arizona is a proper noun.\n",
        "\n",
        "There are various PoS tagging techniques:\n",
        "\n",
        "1.Lexical based Methods\n",
        "\n",
        "2.Rule based Methods\n",
        "\n",
        "3.Probablisitic Methods\n",
        "\n",
        "4.Deep Learning Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlMilVt1Oymj"
      },
      "source": [
        "from nltk import pos_tag, word_tokenize"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe_zQbz4O2d5",
        "outputId": "983d03eb-5ba5-4535-fe44-9fbada073b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = \"Can you please buy me an Arizona tea\"\n",
        "tokens = word_tokenize(text)\n",
        "tokens"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can', 'you', 'please', 'buy', 'me', 'an', 'Arizona', 'tea']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV_E99j3PVuA",
        "outputId": "2634c184-84ad-41b3-91cf-2028601edeb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "t = pos_tag(tokens)\n",
        "t"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Can', 'MD'),\n",
              " ('you', 'PRP'),\n",
              " ('please', 'VB'),\n",
              " ('buy', 'VB'),\n",
              " ('me', 'PRP'),\n",
              " ('an', 'DT'),\n",
              " ('Arizona', 'NNP'),\n",
              " ('tea', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4iL8e5jPhvB"
      },
      "source": [
        "#CRF (Conditional Random Fields)\n",
        "\n",
        "CRF or Conditional Random Fields is a discriminant model for sequences data similar to MEMM(Maximum\n",
        "Entropy Markov Model). It models the dependency between each state and the entire input sequences.CRF\n",
        "overcomes the label bias issue by using global normalizer.\n",
        "\n",
        "In CRF, a set of feature functions are defined to extract features for each word in a sentence. Some examples of\n",
        "feature functions are: is the first letter of the word capitalised, what the suffix and prefix of the word, what is the\n",
        "previous word, is it the first or the last word of the sentence, is it a number \n",
        "etc.\n",
        "\n",
        "#Uses of CRF\n",
        "\n",
        "Gene prediction, NLP Part of Speech (POS) Tagging, NLP Named Entity Recognition (NER)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTkz_Rx_PvYZ"
      },
      "source": [
        "# Importing the dataset and analyzing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ums4bbPVxM",
        "outputId": "cdc98265-16d7-47c1-9d5a-6a4e8e706ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
        "print(\"Number of Tagged Sentences \",len(tagged_sentence))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Tagged Sentences  3914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYf5x0ZiPa4f",
        "outputId": "0c7bfb1c-79e2-40f1-a9a7-e0ba4f9c94aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tagged_words=[tup for sent in tagged_sentence for tup in sent]\n",
        "print(\"Total Number of Tagged words\", len(tagged_words))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Tagged words 100676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRKzJyYzQIjG",
        "outputId": "ad49589d-8c83-47cc-8553-ccd550b5898e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab=set([word for word,tag in tagged_words])\n",
        "print(\"Vocabulary of the Corpus\",len(vocab))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary of the Corpus 12408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEMcfyLRQImx",
        "outputId": "898e3d9e-7dab-4c37-d247-3980e1a33247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tags=set([tag for word,tag in tagged_words])\n",
        "print(\"Number of Tags in the Corpus \",len(tags))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Tags in the Corpus  12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOdFDKiHQUYC"
      },
      "source": [
        "# Splitting the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfJ3QsTBQIsY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(tagged_sentence,test_size=0.2,random_state=1234)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-FXlmwLQafg"
      },
      "source": [
        "Train Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWWwKMy1QZgW",
        "outputId": "54d93c41-e335-4d99-a919-619a651c85d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWhzHnDCQeHX"
      },
      "source": [
        "Test Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-7gzrEgQjfq",
        "outputId": "5acf8351-86a6-42b7-d4ab-9363c7c3eba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_set)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk72rJBTQriX"
      },
      "source": [
        "# Creating the feature function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lvYeWiQxSO"
      },
      "source": [
        "import re\n",
        "def features(sentence,index):\n",
        "  ### sentence is of the form [w1,w2,w3,..], index is the position of the word in the sentence\n",
        "  return {\n",
        "    'is_first_capital':int(sentence[index][0].isupper()),\n",
        "  'is_first_word': int(index==0),\n",
        "    'is_last_word':int(index==len(sentence)-1),\n",
        "    'is_complete_capital': int(sentence[index].upper()==sentence[index]),\n",
        "    'prev_word':'' if index==0 else sentence[index-1],\n",
        "    'next_word':'' if index==len(sentence)-1 else sentence[index+1],\n",
        "    'is_numeric':int(sentence[index].isdigit()),\n",
        "    'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*[a-zA-Z])',sentence[index])))),\n",
        "    'prefix_1':sentence[index][0],\n",
        "    'prefix_2': sentence[index][:2],\n",
        "    'prefix_3':sentence[index][:3],\n",
        "    'prefix_4':sentence[index][:4],\n",
        "    'suffix_1':sentence[index][-1],\n",
        "    'suffix_2':sentence[index][-2:],\n",
        "    'suffix_3':sentence[index][-3:],\n",
        "    'suffix_4':sentence[index][-4:],\n",
        "    'word_has_hyphen': 1 if '-' in sentence[index] else 0\n",
        "}\n",
        "def untag(sentence):\n",
        "  return [word for word,tag in sentence]\n",
        "def prepareData(tagged_sentences):\n",
        "  X,y=[],[]\n",
        "  for sentences in tagged_sentences:\n",
        "    X.append([features(untag(sentences), index) for index in range(len(sentences))])\n",
        "    y.append([tag for word,tag in sentences])\n",
        "  return X,y"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA3uSCzuReml",
        "outputId": "4b6e72c9-2ad5-4b5c-efbc-4df4c6e162b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train,y_train=prepareData(train_set)\n",
        "print(len(X_train))\n",
        "\n",
        "X_test,y_test=prepareData(test_set)\n",
        "print(len(X_test))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3131\n",
            "783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8K1SF3NRl44"
      },
      "source": [
        "Installing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECtghEgDRjZr",
        "outputId": "e9650fb9-7ddf-4cd3-a81a-a84b893a7d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I9Gw4XNRvib"
      },
      "source": [
        "# Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpZezkPSRwzB",
        "outputId": "234fb60c-68b2-4de9-8f6b-31f7ecc94c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from sklearn_crfsuite import CRF\n",
        "crf = CRF(\n",
        "  algorithm='lbfgs',\n",
        "  c1=0.01,\n",
        "  c2=0.1,\n",
        "  max_iterations=100,\n",
        "  all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.01, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h7FXVWgSE-b"
      },
      "source": [
        "# Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLItu289SGit",
        "outputId": "ac9bf6c8-490d-4883-b388-c6018f748cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite import scorers\n",
        "y_pred=crf.predict(X_test)\n",
        "y_pred_train=crf.predict(X_train)\n",
        "\n",
        "print(\"F1 score on Test Data \")\n",
        "print(metrics.flat_f1_score(y_test, y_pred,average='weighted',labels=crf.classes_))\n",
        "\n",
        "print(\"F1 score on Training Data \")\n",
        "metrics.flat_f1_score(y_train, y_pred_train,average='weighted',labels=crf.classes_)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on Test Data \n",
            "0.9738471726864286\n",
            "F1 score on Training Data \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9963402924209424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5P01r-ySGrH",
        "outputId": "93efaa27-04ba-436e-a13c-a6dea4decd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(metrics.flat_classification_report(y_test, y_pred, labels=crf.classes_, digits=3))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADP      0.979     0.985     0.982      1869\n",
            "        NOUN      0.966     0.977     0.972      5606\n",
            "        CONJ      0.994     0.994     0.994       480\n",
            "        VERB      0.964     0.960     0.962      2722\n",
            "         ADJ      0.911     0.874     0.892      1274\n",
            "           .      1.000     1.000     1.000      2354\n",
            "           X      1.000     0.997     0.998      1278\n",
            "         NUM      0.991     0.993     0.992       671\n",
            "         DET      0.994     0.995     0.994      1695\n",
            "         ADV      0.927     0.909     0.918       585\n",
            "        PRON      0.998     0.998     0.998       562\n",
            "         PRT      0.979     0.982     0.980       614\n",
            "\n",
            "    accuracy                          0.974     19710\n",
            "   macro avg      0.975     0.972     0.974     19710\n",
            "weighted avg      0.974     0.974     0.974     19710\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}